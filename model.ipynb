{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path=\"Mediapipe_csv_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frane=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pose_0_x</th>\n",
       "      <th>pose_0_y</th>\n",
       "      <th>pose_0_z</th>\n",
       "      <th>pose_0_visibility</th>\n",
       "      <th>pose_1_x</th>\n",
       "      <th>pose_1_y</th>\n",
       "      <th>pose_1_z</th>\n",
       "      <th>pose_1_visibility</th>\n",
       "      <th>pose_2_x</th>\n",
       "      <th>pose_2_y</th>\n",
       "      <th>...</th>\n",
       "      <th>right_hand_18_x</th>\n",
       "      <th>right_hand_18_y</th>\n",
       "      <th>right_hand_18_z</th>\n",
       "      <th>right_hand_19_x</th>\n",
       "      <th>right_hand_19_y</th>\n",
       "      <th>right_hand_19_z</th>\n",
       "      <th>right_hand_20_x</th>\n",
       "      <th>right_hand_20_y</th>\n",
       "      <th>right_hand_20_z</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498307</td>\n",
       "      <td>0.597076</td>\n",
       "      <td>-0.606710</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.508464</td>\n",
       "      <td>0.564415</td>\n",
       "      <td>-0.583276</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.515995</td>\n",
       "      <td>0.563786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABSCOND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498279</td>\n",
       "      <td>0.596022</td>\n",
       "      <td>-0.600280</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.508525</td>\n",
       "      <td>0.563733</td>\n",
       "      <td>-0.577851</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.516003</td>\n",
       "      <td>0.563310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABSCOND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.498312</td>\n",
       "      <td>0.595275</td>\n",
       "      <td>-0.580530</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.508645</td>\n",
       "      <td>0.563150</td>\n",
       "      <td>-0.557377</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.516038</td>\n",
       "      <td>0.562847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABSCOND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.498371</td>\n",
       "      <td>0.594620</td>\n",
       "      <td>-0.568087</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0.508723</td>\n",
       "      <td>0.562634</td>\n",
       "      <td>-0.544764</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.516058</td>\n",
       "      <td>0.562404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABSCOND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.498440</td>\n",
       "      <td>0.594223</td>\n",
       "      <td>-0.571533</td>\n",
       "      <td>0.999981</td>\n",
       "      <td>0.508799</td>\n",
       "      <td>0.562267</td>\n",
       "      <td>-0.548652</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.516081</td>\n",
       "      <td>0.562085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABSCOND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67426</th>\n",
       "      <td>0.537084</td>\n",
       "      <td>0.467278</td>\n",
       "      <td>-0.554316</td>\n",
       "      <td>0.996545</td>\n",
       "      <td>0.550541</td>\n",
       "      <td>0.443692</td>\n",
       "      <td>-0.519437</td>\n",
       "      <td>0.986121</td>\n",
       "      <td>0.557418</td>\n",
       "      <td>0.448450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67427</th>\n",
       "      <td>0.536741</td>\n",
       "      <td>0.467621</td>\n",
       "      <td>-0.600482</td>\n",
       "      <td>0.996675</td>\n",
       "      <td>0.550430</td>\n",
       "      <td>0.443740</td>\n",
       "      <td>-0.568386</td>\n",
       "      <td>0.986407</td>\n",
       "      <td>0.557099</td>\n",
       "      <td>0.448429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393912</td>\n",
       "      <td>0.914119</td>\n",
       "      <td>-0.037799</td>\n",
       "      <td>0.401047</td>\n",
       "      <td>0.921260</td>\n",
       "      <td>-0.029267</td>\n",
       "      <td>0.403612</td>\n",
       "      <td>0.915940</td>\n",
       "      <td>-0.022153</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67428</th>\n",
       "      <td>0.536561</td>\n",
       "      <td>0.468375</td>\n",
       "      <td>-0.563149</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.550381</td>\n",
       "      <td>0.443924</td>\n",
       "      <td>-0.535783</td>\n",
       "      <td>0.986792</td>\n",
       "      <td>0.556885</td>\n",
       "      <td>0.448447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410493</td>\n",
       "      <td>0.927779</td>\n",
       "      <td>-0.033568</td>\n",
       "      <td>0.415468</td>\n",
       "      <td>0.932268</td>\n",
       "      <td>-0.024187</td>\n",
       "      <td>0.415681</td>\n",
       "      <td>0.925296</td>\n",
       "      <td>-0.015931</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67429</th>\n",
       "      <td>0.536602</td>\n",
       "      <td>0.468447</td>\n",
       "      <td>-0.555374</td>\n",
       "      <td>0.996998</td>\n",
       "      <td>0.550378</td>\n",
       "      <td>0.443880</td>\n",
       "      <td>-0.523718</td>\n",
       "      <td>0.987465</td>\n",
       "      <td>0.556726</td>\n",
       "      <td>0.448260</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438260</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>-0.032302</td>\n",
       "      <td>0.442374</td>\n",
       "      <td>0.978156</td>\n",
       "      <td>-0.023837</td>\n",
       "      <td>0.440963</td>\n",
       "      <td>0.970424</td>\n",
       "      <td>-0.015725</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67430</th>\n",
       "      <td>0.536624</td>\n",
       "      <td>0.468454</td>\n",
       "      <td>-0.544480</td>\n",
       "      <td>0.997248</td>\n",
       "      <td>0.550342</td>\n",
       "      <td>0.443634</td>\n",
       "      <td>-0.510161</td>\n",
       "      <td>0.988526</td>\n",
       "      <td>0.556592</td>\n",
       "      <td>0.447727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453663</td>\n",
       "      <td>1.021220</td>\n",
       "      <td>-0.019725</td>\n",
       "      <td>0.455362</td>\n",
       "      <td>1.036372</td>\n",
       "      <td>-0.015272</td>\n",
       "      <td>0.455628</td>\n",
       "      <td>1.045405</td>\n",
       "      <td>-0.011772</td>\n",
       "      <td>WRONG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67431 rows × 259 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pose_0_x  pose_0_y  pose_0_z  pose_0_visibility  pose_1_x  pose_1_y  \\\n",
       "0      0.498307  0.597076 -0.606710           0.999984  0.508464  0.564415   \n",
       "1      0.498279  0.596022 -0.600280           0.999983  0.508525  0.563733   \n",
       "2      0.498312  0.595275 -0.580530           0.999983  0.508645  0.563150   \n",
       "3      0.498371  0.594620 -0.568087           0.999982  0.508723  0.562634   \n",
       "4      0.498440  0.594223 -0.571533           0.999981  0.508799  0.562267   \n",
       "...         ...       ...       ...                ...       ...       ...   \n",
       "67426  0.537084  0.467278 -0.554316           0.996545  0.550541  0.443692   \n",
       "67427  0.536741  0.467621 -0.600482           0.996675  0.550430  0.443740   \n",
       "67428  0.536561  0.468375 -0.563149           0.996817  0.550381  0.443924   \n",
       "67429  0.536602  0.468447 -0.555374           0.996998  0.550378  0.443880   \n",
       "67430  0.536624  0.468454 -0.544480           0.997248  0.550342  0.443634   \n",
       "\n",
       "       pose_1_z  pose_1_visibility  pose_2_x  pose_2_y  ...  right_hand_18_x  \\\n",
       "0     -0.583276           0.999963  0.515995  0.563786  ...         0.000000   \n",
       "1     -0.577851           0.999961  0.516003  0.563310  ...         0.000000   \n",
       "2     -0.557377           0.999960  0.516038  0.562847  ...         0.000000   \n",
       "3     -0.544764           0.999958  0.516058  0.562404  ...         0.000000   \n",
       "4     -0.548652           0.999956  0.516081  0.562085  ...         0.000000   \n",
       "...         ...                ...       ...       ...  ...              ...   \n",
       "67426 -0.519437           0.986121  0.557418  0.448450  ...         0.000000   \n",
       "67427 -0.568386           0.986407  0.557099  0.448429  ...         0.393912   \n",
       "67428 -0.535783           0.986792  0.556885  0.448447  ...         0.410493   \n",
       "67429 -0.523718           0.987465  0.556726  0.448260  ...         0.438260   \n",
       "67430 -0.510161           0.988526  0.556592  0.447727  ...         0.453663   \n",
       "\n",
       "       right_hand_18_y  right_hand_18_z  right_hand_19_x  right_hand_19_y  \\\n",
       "0             0.000000         0.000000         0.000000         0.000000   \n",
       "1             0.000000         0.000000         0.000000         0.000000   \n",
       "2             0.000000         0.000000         0.000000         0.000000   \n",
       "3             0.000000         0.000000         0.000000         0.000000   \n",
       "4             0.000000         0.000000         0.000000         0.000000   \n",
       "...                ...              ...              ...              ...   \n",
       "67426         0.000000         0.000000         0.000000         0.000000   \n",
       "67427         0.914119        -0.037799         0.401047         0.921260   \n",
       "67428         0.927779        -0.033568         0.415468         0.932268   \n",
       "67429         0.970443        -0.032302         0.442374         0.978156   \n",
       "67430         1.021220        -0.019725         0.455362         1.036372   \n",
       "\n",
       "       right_hand_19_z  right_hand_20_x  right_hand_20_y  right_hand_20_z  \\\n",
       "0             0.000000         0.000000         0.000000         0.000000   \n",
       "1             0.000000         0.000000         0.000000         0.000000   \n",
       "2             0.000000         0.000000         0.000000         0.000000   \n",
       "3             0.000000         0.000000         0.000000         0.000000   \n",
       "4             0.000000         0.000000         0.000000         0.000000   \n",
       "...                ...              ...              ...              ...   \n",
       "67426         0.000000         0.000000         0.000000         0.000000   \n",
       "67427        -0.029267         0.403612         0.915940        -0.022153   \n",
       "67428        -0.024187         0.415681         0.925296        -0.015931   \n",
       "67429        -0.023837         0.440963         0.970424        -0.015725   \n",
       "67430        -0.015272         0.455628         1.045405        -0.011772   \n",
       "\n",
       "          word  \n",
       "0      ABSCOND  \n",
       "1      ABSCOND  \n",
       "2      ABSCOND  \n",
       "3      ABSCOND  \n",
       "4      ABSCOND  \n",
       "...        ...  \n",
       "67426    WRONG  \n",
       "67427    WRONG  \n",
       "67428    WRONG  \n",
       "67429    WRONG  \n",
       "67430    WRONG  \n",
       "\n",
       "[67431 rows x 259 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        word_meaning=file_name.split('_')[0]\n",
    "        file_path=os.path.join(folder_path,file_name)\n",
    "        df=pd.read_csv(file_path)\n",
    "        df['word']=word_meaning\n",
    "        data_frane.append(df)\n",
    "final=pd.concat(data_frane,ignore_index=True)\n",
    "final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"ISl_model.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Hyperparameters: {'num_leaves': 100, 'n_estimators': 200, 'min_data_in_leaf': 50, 'max_depth': 10, 'learning_rate': 0.05, 'boosting_type': 'dart'}\n",
      "Accuracy: 0.8946\n",
      "Classification Report:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          ABSCOND       0.79      0.92      0.85        12\n",
      "           AFFIRM       1.00      0.86      0.92        21\n",
      "      AFGHANISTAN       1.00      0.91      0.95        22\n",
      "           AFRICA       0.93      0.93      0.93        15\n",
      "   ANDHRA PRADESH       1.00      0.69      0.82        13\n",
      "        ARGENTINA       0.84      0.89      0.86        18\n",
      "         BACKDOOR       0.89      0.67      0.76        12\n",
      "           BACKUP       1.00      0.82      0.90        11\n",
      "            BIHAR       0.94      0.88      0.91        17\n",
      "        BLUETOOTH       0.89      1.00      0.94        16\n",
      "           BUDGET       0.94      0.94      0.94        17\n",
      "           CANADA       0.93      0.76      0.84        17\n",
      "          CHENNAI       0.93      0.76      0.84        17\n",
      "   CHEST EXPANDER       0.92      0.86      0.89        14\n",
      "  COLD ROOM UNITS       1.00      0.78      0.88         9\n",
      "     CONSTRUCTION       1.00      0.78      0.88         9\n",
      "   CZECH REPUBLIC       1.00      0.86      0.92        14\n",
      "         DELEGATE       1.00      0.67      0.80        18\n",
      "            DELHI       0.93      1.00      0.96        13\n",
      "          DENMARK       0.93      0.81      0.87        16\n",
      "      DENTAL XRAY       1.00      0.85      0.92        13\n",
      "          ENGLAND       0.91      1.00      0.95        10\n",
      "     EXERCISE MAT       1.00      0.87      0.93        23\n",
      "          GANGTOK       1.00      1.00      1.00        13\n",
      "        GENERATOR       0.83      0.80      0.82        25\n",
      "              GOA       0.83      0.67      0.74        15\n",
      "          GUJARAT       1.00      1.00      1.00        12\n",
      "          HARYANA       0.93      0.88      0.90        16\n",
      "       HEART BEAT       0.97      1.00      0.98        29\n",
      " HIMACHAL PRADESH       0.88      0.78      0.82        18\n",
      "               IN       0.82      0.86      0.84       229\n",
      "     INAUGURATION       0.80      0.90      0.84       319\n",
      "          INCLUDE       1.00      0.54      0.70        13\n",
      "     INDEX FINGER       0.83      0.67      0.74        15\n",
      "         INFORMAL       0.84      0.82      0.83       198\n",
      "        INSURANCE       0.90      0.89      0.89       143\n",
      "        INTERPRET       0.89      0.92      0.90       211\n",
      "          INVOLVE       0.90      0.79      0.84       193\n",
      "             IRON       0.87      0.86      0.86       277\n",
      "               IT       0.84      0.86      0.85       179\n",
      "             ITCH       0.91      0.86      0.89       228\n",
      "           JAIPUR       1.00      0.83      0.91        18\n",
      "JAMMU AND KASHMIR       0.89      0.67      0.76        12\n",
      "          JOBLESS       0.82      0.91      0.86       349\n",
      "             JOIN       0.88      0.80      0.84       125\n",
      "           KARATE       0.93      0.91      0.92       303\n",
      "             KEEP       0.87      0.92      0.89       232\n",
      "            KENYA       0.94      0.88      0.91        17\n",
      "              KEY       0.93      0.92      0.92       198\n",
      "             KILL       0.86      0.84      0.85       193\n",
      "            KNIFE       0.91      0.92      0.92       212\n",
      "            KNOCK       0.94      0.94      0.94       216\n",
      "           KUWAIT       0.86      0.75      0.80        16\n",
      "             LESS       0.91      0.84      0.88       196\n",
      "            LEVEL       0.89      0.87      0.88       264\n",
      "          LICENSE       0.88      0.90      0.89       277\n",
      "             LINK       0.89      0.78      0.83       226\n",
      "             LOCK       0.97      0.91      0.94       265\n",
      "            LOGIC       0.86      0.95      0.90       256\n",
      "            LOGIN       1.00      0.43      0.60         7\n",
      "      MAHARASHTRA       1.00      1.00      1.00        18\n",
      "             MALI       0.50      0.50      0.50        12\n",
      "            MATCH       0.96      0.96      0.96       328\n",
      "          MAXIMUM       0.98      0.91      0.95       237\n",
      "             MEAN       0.90      0.90      0.90       201\n",
      "          MEETING       0.93      0.94      0.93       283\n",
      "              ODD       0.87      0.89      0.88       122\n",
      "         PLUMBING       0.77      0.92      0.84        26\n",
      "    POWER SOCKETS       0.93      0.87      0.90        31\n",
      "          RESTART       0.77      0.83      0.80        12\n",
      "         SHUTDOWN       0.67      0.67      0.67        12\n",
      "             SWAB       0.96      0.92      0.94        24\n",
      "             TAKE       0.90      0.95      0.92       241\n",
      "             TALK       0.88      0.89      0.89       298\n",
      "              TEA       0.97      0.99      0.98       402\n",
      "          TEACHER       0.94      0.91      0.93       293\n",
      "       TECHNOLOGY       0.94      0.92      0.93       320\n",
      "            UNITY       0.91      0.90      0.91       341\n",
      "               UP       0.88      0.91      0.89       225\n",
      "            URINE       0.91      0.77      0.83        13\n",
      "          UROLOGY       1.00      0.92      0.96        26\n",
      "         VACATION       0.93      0.91      0.92       226\n",
      "            VIRUS       0.84      0.96      0.90        27\n",
      "             VISA       0.78      0.84      0.81       294\n",
      "             VOTE       0.93      0.91      0.92       291\n",
      "          WEBSITE       0.86      0.87      0.86       206\n",
      "          WEDDING       0.89      0.94      0.91       139\n",
      "             WEST       0.89      0.67      0.77       137\n",
      "             WHAT       0.90      0.88      0.89       198\n",
      "         WHATSAPP       0.96      0.96      0.96       263\n",
      "            WHILE       0.80      0.86      0.83       274\n",
      "           WICKET       0.87      0.97      0.91       364\n",
      "             WIFI       0.93      0.87      0.90       257\n",
      "        WIKIPEDIA       0.77      0.77      0.77        13\n",
      "             WINE       0.93      0.95      0.94       267\n",
      "             WOOD       0.89      0.85      0.87       248\n",
      "             WORD       0.90      0.93      0.92       192\n",
      "         WORKSHOP       0.85      0.90      0.88       289\n",
      "            WOUND       0.93      0.84      0.88       218\n",
      "            WRONG       0.90      0.96      0.93       257\n",
      "\n",
      "         accuracy                           0.89     13487\n",
      "        macro avg       0.90      0.86      0.88     13487\n",
      "     weighted avg       0.90      0.89      0.89     13487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('ISl_model')  # Replace 'ISl_model' with your actual filename\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('word', axis=1)\n",
    "y = df['word']\n",
    "\n",
    "# Encode the target variable (since it's a string type)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Define the LightGBM classifier\n",
    "model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 50, 100],\n",
    "    'max_depth': [-1, 5, 10, 20],\n",
    "    'min_data_in_leaf': [10, 20, 50, 100],\n",
    "    'boosting_type': ['gbdt', 'dart'],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "}\n",
    "\n",
    "# Set up cross-validation with stratification\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,  # Adjust for more iterations\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Predict using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If training LIGHTGBM model train with follwoing Hyper parameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Hyperparameters: {'num_leaves': 100, 'n_estimators': 200, 'min_data_in_leaf': 50, 'max_depth': 10, 'learning_rate': 0.05, 'boosting_type': 'dart'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 67431\n",
      "Filtered dataset size: 67431\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ISl_model.csv')  # Replace with your actual filename\n",
    "\n",
    "# Remove labels with fewer than 3 occurrences\n",
    "label_counts = df['word'].value_counts()\n",
    "filtered_labels = label_counts[label_counts >= 3].index\n",
    "df_filtered = df[df['word'].isin(filtered_labels)]\n",
    "\n",
    "# Verify the filtered dataset\n",
    "print(f\"Original dataset size: {df.shape[0]}\")\n",
    "print(f\"Filtered dataset size: {df_filtered.shape[0]}\")\n",
    "\n",
    "# Continue with data preprocessing...\n",
    "X = df_filtered.drop('word', axis=1)\n",
    "y = df_filtered['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"ISl_model.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['word'])  # Replace 'target' with your actual column name\n",
    "y = df['word']\n",
    "\n",
    "# Encode string target labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=len(label_encoder.classes_), random_state=42)\n",
    "\n",
    "# Hyperparameter grid (adjusted for your dataset size)\n",
    "param_grid = {\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [200, 300, 500],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.8],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid,\n",
    "                           cv=3, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model evaluation\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to predict\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original string labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test_decoded, y_pred_decoded))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_decoded, y_pred_decoded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
